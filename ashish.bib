% Encoding: UTF-8

@InProceedings{pmlr-v70-gupta17a,
  author    = {Chirag Gupta and Arun Sai Suggala and Ankit Goyal and Harsha Vardhan Simhadri and Bhargavi Paranjape and Ashish Kumar and Saurabh Goyal and Raghavendra Udupa and Manik Varma and Prateek Jain},
  title     = {{P}roto{NN}: Compressed and Accurate k{NN} for Resource-scarce Devices},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning},
  year      = {2017},
  editor    = {Doina Precup and Yee Whye Teh},
  volume    = {70},
  series    = {Proceedings of Machine Learning Research},
  pages     = {1331--1340},
  address   = {International Convention Centre, Sydney, Australia},
  month     = {06--11 Aug},
  publisher = {PMLR},
  abstract  = {Several real-world applications require real-time prediction on resource-scarce devices such as an Internet of Things (IoT) sensor. Such applications demand prediction models with small storage and computational complexity that do not compromise significantly on accuracy. In this work, we propose ProtoNN, a novel algorithm that addresses the problem of real-time and accurate prediction on resource-scarce devices. ProtoNN is inspired by k-Nearest Neighbor (KNN) but has several orders lower storage and prediction complexity. ProtoNN models can be deployed even on devices with puny storage and computational power (e.g. an Arduino UNO with 2kB RAM) to get excellent prediction accuracy. ProtoNN derives its strength from three key ideas: a) learning a small number of prototypes to represent the entire training set, b) sparse low dimensional projection of data, c) joint discriminative learning of the projection and prototypes with explicit model size constraint. We conduct systematic empirical evaluation of ProtoNN on a variety of supervised learning tasks (binary, multi-class, multi-label classification) and show that it gives nearly state-of-the-art prediction accuracy on resource-scarce devices while consuming several orders lower storage, and using minimal working memory.},
  pdf       = {http://proceedings.mlr.press/v70/gupta17a/gupta17a.pdf},
  url       = {http://proceedings.mlr.press/v70/gupta17a.html},
}

@InProceedings{pmlr-v70-kumar17a,
  author    = {Ashish Kumar and Saurabh Goyal and Manik Varma},
  title     = {Resource-efficient Machine Learning in 2 {KB} {RAM} for the Internet of Things},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning},
  year      = {2017},
  editor    = {Doina Precup and Yee Whye Teh},
  volume    = {70},
  series    = {Proceedings of Machine Learning Research},
  pages     = {1935--1944},
  address   = {International Convention Centre, Sydney, Australia},
  month     = {06--11 Aug},
  publisher = {PMLR},
  abstract  = {This paper develops a novel tree-based algorithm, called Bonsai, for efficient prediction on IoT devices – such as those based on the Arduino Uno board having an 8 bit ATmega328P microcontroller operating at 16 MHz with no native floating point support, 2 KB RAM and 32 KB read-only flash. Bonsai maintains prediction accuracy while minimizing model size and prediction costs by: (a) developing a tree model which learns a single, shallow, sparse tree with powerful nodes; (b) sparsely projecting all data into a low-dimensional space in which the tree is learnt; and (c) jointly learning all tree and projection parameters. Experimental results on multiple benchmark datasets demonstrate that Bonsai can make predictions in milliseconds even on slow microcontrollers, can fit in KB of memory, has lower battery consumption than all other algorithms while achieving prediction accuracies that can be as much as 30\% higher than state-of-the-art methods for resource-efficient machine learning. Bonsai is also shown to generalize to other resource constrained settings beyond IoT by generating significantly better search results as compared to Bing’s L3 ranker when the model size is restricted to 300 bytes. Bonsai’s code can be downloaded from (http://www.manikvarma.org/code/Bonsai/download.html).},
  pdf       = {http://proceedings.mlr.press/v70/kumar17a/kumar17a.pdf},
  url       = {http://proceedings.mlr.press/v70/kumar17a.html},
}

@Comment{jabref-meta: databaseType:bibtex;}
